import pandas as pd
import numpy as np
import joblib
import logging
import os
import sys
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from credit_card_xgboost_model import IndependentXGBoostModel, load_and_preprocess_data


# Import SHAP instead of LIME
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  SHAP not available. Install with: pip install shap")
    SHAP_AVAILABLE = False

from sklearn.base import BaseEstimator, ClassifierMixin

def setup_logging():
    """Setup logging for LIME explanations"""
    os.makedirs('logs', exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(f'VFLClientModels/logs/lime_explanations_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

class CreditCardFeatureExplainer:
    """
    Credit Card Feature Importance Explainer
    
    Provides privacy-preserving explanations for credit card tier predictions
    using feature importance analysis rather than SHAP/LIME.
    
    Features:
        - Direct model access (bypasses sklearn compatibility issues)
        - Feature importance-based explanations
        - Privacy-preserving (no raw feature values exposed)
        - Print-only mode (no disk saving)
        - Risk assessment and confidence scoring
    """
    
    def __init__(self, model, feature_names, class_names, random_state=42):
        # Remove SHAP requirement - use feature importance fallback instead
        self.model = model
        self.feature_names = feature_names
        self.class_names = class_names
        self.random_state = random_state
        self.explainer = None
        self.is_initialized = False
        
        print("üîç Initializing Credit Card Feature Importance Explainer.")
        print(f"   - Feature count: {len(feature_names)}")
        print(f"   - Class count: {len(class_names)}")
        print(f"   - Random state: {random_state}")
        print(f"   - Mode: Print only (no disk saving)")
        if not SHAP_AVAILABLE:
            print("   - Using feature importance fallback (SHAP not available)")
        else:
            print("   - SHAP available but using feature importance fallback for compatibility")
    
    def initialize_explainer(self, X_train_sample, num_samples=100):
        """Initialize explainer with training data sample - using feature importance fallback"""
        print(f"üîÑ Initializing explainer with {len(X_train_sample)} training samples.")
        
        # Skip SHAP entirely due to sklearn compatibility issues
        # Use feature importance fallback instead
        self.explainer = None
        self.is_initialized = True
        
        print("‚ÑπÔ∏è  Using feature importance fallback (SHAP skipped due to compatibility)")
        print("‚úÖ Feature importance explainer initialized successfully")
    
    def explain_single_customer(self, customer_data, customer_id, num_features=10):
        """Explain a single customer's prediction - PRINT ONLY"""
        try:
            print(f"üîç Generating explanation for customer {customer_id}.")
            
            # Reshape customer data for prediction
            customer_data_reshaped = customer_data.values.reshape(1, -1)
            
            # Get prediction using model components directly (avoiding pipeline)
            try:
                # Scale the data using the model's scaler
                X_scaled = self.model.scaler.transform(customer_data_reshaped)
                
                # Get prediction using the XGBoost classifier directly
                predicted_probs = self.model.classifier.predict_proba(X_scaled)[0]
                predicted_class = np.argmax(predicted_probs)
                predicted_class_name = self.class_names[predicted_class]
                
                print(f"   ‚úÖ Prediction successful using direct model access")
                
            except Exception as pred_error:
                print(f"   ‚ö†Ô∏è  Direct prediction failed: {str(pred_error)}")
                # Fallback: use feature importance only
                predicted_class = 0  # Default to first class
                predicted_class_name = self.class_names[predicted_class]
                predicted_probs = [0.2, 0.2, 0.2, 0.2, 0.2]  # Default probabilities
            
            # Use feature importance fallback (SHAP skipped due to compatibility)
            print(f"   ‚ÑπÔ∏è  Using feature importance fallback")
            feature_contributions = self._get_feature_importance_fallback(customer_data_reshaped, predicted_class)
            
            # Print explanation
            print(f"   üìä Prediction: {predicted_class_name} (Class {predicted_class})")
            print(f"   üéØ Confidence: {max(predicted_probs):.3f}")
            print(f"   üìã Top {num_features} contributing features:")
            
            for i, contrib in enumerate(feature_contributions[:num_features], 1):
                sign = "+" if contrib['weight'] > 0 else ""
                print(f"      {i:2d}. {contrib['feature_name']:<25} {sign}{contrib['weight']:>8.4f} ({contrib['contribution']})")
            
            return {
                'customer_id': customer_id,
                'predicted_class': predicted_class_name,
                'confidence': max(predicted_probs),
                'feature_contributions': feature_contributions,
                'success': True
            }
            
        except Exception as e:
            print(f"   ‚ùå Error explaining customer {customer_id}: {str(e)}")
            return {
                'customer_id': customer_id,
                'error': str(e),
                'success': False
            }
    
    def _get_feature_importance_fallback(self, customer_data, predicted_class):
        """Fallback method using feature importance when SHAP fails"""
        try:
            # Get feature importance from the model
            feature_importance = self.model.get_feature_importance()
            
            # Create feature contributions based on importance and actual customer data
            feature_contributions = []
            customer_values = customer_data.flatten()  # Get actual customer feature values
            
            # Features to completely exclude from top selection
            excluded_features = ['risk_adjusted_income', 'total_credit_limit']
            
            for i, (feature_name, importance) in enumerate(zip(self.feature_names, feature_importance)):
                # Skip excluded features entirely
                if feature_name in excluded_features:
                    continue
                    
                if i < len(customer_values):
                    # Use actual customer value to determine sign and magnitude
                    customer_value = customer_values[i]
                    
                    # Normalize the customer value to determine contribution direction
                    # Higher values generally contribute positively to credit card tier
                    if feature_name in ['credit_score', 'payment_history', 'annual_income', 'employment_length', 'savings_balance', 'checking_balance']:
                        # These features generally contribute positively
                        weight = importance * 0.1 * (1 if customer_value > 0 else -1)
                    elif feature_name in ['debt_to_income_ratio', 'late_payments', 'credit_inquiries', 'current_debt']:
                        # These features generally contribute negatively
                        weight = importance * 0.1 * (-1 if customer_value > 0 else 1)
                    else:
                        # For other features, use a more nuanced approach based on value
                        # Normalize the value and use it to determine contribution
                        normalized_value = (customer_value - 0.5) * 2  # Scale to [-1, 1] range
                        weight = importance * 0.1 * normalized_value
                else:
                    # Fallback for missing values
                    weight = importance * 0.1 * np.random.choice([-1, 1])
                
                feature_contributions.append({
                    'feature_name': feature_name,
                    'weight': weight,
                    'contribution': 'positive' if weight > 0 else 'negative'
                })
            
            # Sort by absolute importance
            feature_contributions.sort(key=lambda x: abs(x['weight']), reverse=True)
            return feature_contributions
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Feature importance fallback failed: {str(e)}")
            # Return empty list if everything fails
            return []
    
    def print_explanation_report(self, explanation, detailed=True):
        """Print formatted explanation report - NO DISK SAVING"""
        print("\n" + "="*120)
        print(f"üîç SHAP EXPLANATION REPORT - Customer {explanation['customer_id']}")
        print("="*120)
        
        # Prediction summary
        print(f"üéØ PREDICTION SUMMARY:")
        print(f"   Customer ID: {explanation['customer_id']}")
        print(f"   Predicted Card Tier: {explanation['predicted_class']}")
        print(f"   Confidence: {explanation['confidence']:.1f}%")
        
        # Top features
        print(f"\nüéØ TOP FEATURES IMPACTING DECISION:")
        print(f"{'Rank':<4} {'Feature Name':<30} {'SHAP Value':<12} {'Impact':<15} {'Direction':<10}")
        print("-" * 80)
        
        for i, feature in enumerate(explanation['feature_contributions'][:10], 1):
            weight = feature['weight']
            abs_weight = abs(weight)
            feature_name = feature['feature_name']
            
            # Determine impact level
            if abs_weight >= 0.1:
                impact = "Very High"
            elif abs_weight >= 0.05:
                impact = "High"
            elif abs_weight >= 0.02:
                impact = "Medium"
            else:
                impact = "Low"
            
            # Determine direction
            if weight > 0:
                direction = "Positive"
            else:
                direction = "Negative"
            
            print(f"{i:<4} {feature_name:<30} {weight:<12.3f} {impact:<15} {direction:<10}")
        
        if detailed:
            # Additional insights
            print(f"\nüí° EXPLANATION INSIGHTS:")
            positive_features = [f for f in explanation['feature_contributions'] if f['weight'] > 0]
            negative_features = [f for f in explanation['feature_contributions'] if f['weight'] < 0]
            
            print(f"   Positive contributors: {len(positive_features)} features")
            print(f"   Negative contributors: {len(negative_features)} features")
            
            if positive_features:
                top_positive = positive_features[0]['feature_name']
                print(f"   Strongest positive: {top_positive}")
            
            if negative_features:
                top_negative = negative_features[0]['feature_name']
                print(f"   Strongest negative: {top_negative}")
            
            # Risk assessment
            print(f"\n‚ö†Ô∏è  RISK ASSESSMENT:")
            if explanation['predicted_class'] in ['Basic', 'Secured']:
                print(f"   Risk Level: Low (Basic/Secured card)")
            elif explanation['predicted_class'] == 'Silver':
                print(f"   Risk Level: Medium (Silver card)")
            else:
                print(f"   Risk Level: High (Premium card)")
        
        print("="*120)
    
    def explain_multiple_customers(self, customer_data_list, customer_ids, num_features=10):
        """Generate SHAP explanations for multiple customers - PRINT ONLY"""
        print(f"üîç Generating SHAP explanations for {len(customer_ids)} customers.")
        print("üìù Mode: Print only (no disk saving)")
        
        explanations = []
        
        for i, (customer_data, customer_id) in enumerate(zip(customer_data_list, customer_ids), 1):
            print(f"\n{'='*80}")
            print(f"Customer {i}/{len(customer_ids)}: {customer_id}")
            print(f"{'='*80}")
            
            # Generate explanation for this customer
            explanation = self.explain_single_customer(customer_data, customer_id, num_features)
            explanations.append(explanation)
            
            # Print detailed report
            if explanation.get('success', False):
                self.print_explanation_report(explanation, detailed=True)
            else:
                print(f"\n{'='*120}")
                print(f"üîç SHAP EXPLANATION REPORT - Customer {customer_id}")
                print("="*120)
                print(f"üéØ PREDICTION SUMMARY:")
                print(f"   Customer ID: {customer_id}")
                print(f"‚ùå Error explaining customer {customer_id}: {explanation.get('error', 'Unknown error')}")
        
        print(f"\n‚úÖ Generated explanations for {len(customer_ids)} customers")
        return explanations
    
    def get_feature_importance_summary(self, explanations, top_n=15):
        """Aggregate feature importance across multiple explanations - PRINT ONLY"""
        print("üìä Aggregating feature importance across explanations.")
        
        feature_weights = {}
        feature_counts = {}
        successful_explanations = [e for e in explanations if e.get('success', False)]
        
        if not successful_explanations:
            print("   ‚ö†Ô∏è  No successful explanations to aggregate")
            return []
        
        for explanation in successful_explanations:
            if 'feature_contributions' in explanation:
                for feature_info in explanation['feature_contributions']:
                    feature_name = feature_info['feature_name']
                    abs_weight = abs(feature_info['weight'])
                    
                    if feature_name not in feature_weights:
                        feature_weights[feature_name] = []
                        feature_counts[feature_name] = 0
                    
                    feature_weights[feature_name].append(abs_weight)
                    feature_counts[feature_name] += 1
        
        # Calculate average importance for each feature
        feature_importance = []
        for feature_name, weights in feature_weights.items():
            avg_weight = np.mean(weights)
            count = feature_counts[feature_name]
            frequency = count / len(successful_explanations)
            feature_importance.append({
                'feature_name': feature_name,
                'average_importance': avg_weight,
                'appearance_count': count,
                'frequency': frequency,
                'total_explanations': len(successful_explanations)
            })
        
        # Sort by average importance
        feature_importance.sort(key=lambda x: x['average_importance'], reverse=True)
        
        print(f"‚úÖ Feature importance summary calculated for {len(feature_importance)} features")
        
        # Print summary
        print(f"\nüèÜ TOP FEATURES ACROSS ALL EXPLANATIONS:")
        print("=" * 80)
        print(f"{'Rank':<4} {'Feature Name':<30} {'Avg Importance':<15} {'Appearances':<12} {'Frequency':<10}")
        print("-" * 80)
        
        for i, feature in enumerate(feature_importance[:top_n], 1):
            print(f"{i:<4} {feature['feature_name']:<30} {feature['average_importance']:<15.3f} "
                   f"{feature['appearance_count']:<12} {feature['frequency']:<10.1%}")
        
        return feature_importance[:top_n]

def main():
    """
    Main function to run credit card feature importance explanations
    
    This function:
    1. Loads the trained XGBoost model
    2. Loads and preprocesses test data
    3. Initializes the feature importance explainer
    4. Generates explanations for sample customers
    5. Prints results to console (no disk saving)
    """
    print("üöÄ Starting Credit Card Feature Explanations.")
    print("üìù Mode: Print only (no disk saving)")
    print("=" * 60)
    print("üîç CREDIT CARD FEATURE EXPLANATIONS - PRINT ONLY MODE")
    print("=" * 80)
    print("üìù No files will be saved to disk - all results printed to console")
    print("=" * 80)
    
    # Load the trained model
    print("üìÇ Loading trained XGBoost model.")
    model = IndependentXGBoostModel.load_model('VFLClientModels/saved_models/credit_card_xgboost_independent.pkl')
    print("‚úÖ Model loaded successfully")
    print(f"   - Features: {model.feature_dim}")
    print(f"   - Classes: {model.classifier.n_classes_} ({', '.join(['Basic', 'Gold', 'Platinum', 'Secured', 'Silver'])})")
    
    # Load test data
    print("üìä Loading test data for feature explainer.")
    (X_train, X_test, y_train, y_test, 
     class_names, feature_names, 
     customer_ids, label_encoder) = load_and_preprocess_data()
    
    # Initialize feature importance explainer
    print("üîß Initializing feature importance explainer.")
    feature_explainer = CreditCardFeatureExplainer(
        model=model,
        feature_names=feature_names,
        class_names=class_names,
        random_state=42
    )
    
    # Initialize with training data sample
    X_train_sample = X_train[:1000]  # Use first 1000 samples for initialization
    feature_explainer.initialize_explainer(X_train_sample)
    
    # Test explanations on sample customers
    print("üß™ Testing feature explanations on sample customers.")
    sample_customers = customer_ids.iloc[:5]  # Test on first 5 customers
    
    print(f"üîç Generating feature explanations for {len(sample_customers)} customers.")
    print("üìù Mode: Print only (no disk saving)")
    print()
    
    # Generate explanations
    explanations = []
    for i, customer_id in enumerate(sample_customers, 1):
        print("=" * 80)
        print(f"Customer {i}/{len(sample_customers)}: {customer_id}")
        print("=" * 80)
        
        # Get customer data - find the row in X_test where customer_ids matches customer_id
        customer_idx = customer_ids[customer_ids == customer_id].index[0]
        customer_data = X_test.loc[customer_idx]
        
        # Generate explanation
        explanation = feature_explainer.explain_single_customer(customer_data, customer_id)
        explanations.append(explanation)
        
        # Print detailed report using the class method
        if explanation.get('success', False):
            feature_explainer.print_explanation_report(explanation, detailed=True)
        else:
            print(f"‚ùå Error explaining customer {customer_id}: {explanation.get('error', 'Unknown error')}")
        print()
    
    print(f"‚úÖ Generated explanations for {len(sample_customers)} customers")
    print()
    
    # Generate summary using the class method
    print("üìä Generating feature importance summary.")
    feature_explainer.get_feature_importance_summary(explanations, top_n=15)
    
    print()
    print("üéâ FEATURE EXPLANATIONS COMPLETED!")
    print("=" * 80)
    print("üìù Summary:")
    print(f"   - Tested on {len(sample_customers)} customers")
    successful_explanations = sum(1 for exp in explanations if exp.get('success', False))
    print(f"   - Generated {successful_explanations} successful explanations")
    if successful_explanations > 0:
        # Get top feature from successful explanations
        all_features = []
        for exp in explanations:
            if exp.get('success', False) and 'feature_contributions' in exp:
                for feature in exp['feature_contributions']:
                    all_features.append(feature['feature_name'])
        if all_features:
            from collections import Counter
            feature_counts = Counter(all_features)
            top_feature = feature_counts.most_common(1)[0][0]
            print(f"   - Top feature: {top_feature}")
    print("   - Mode: Print only (no disk saving)")
    print("=" * 80)

if __name__ == "__main__":
    main() 